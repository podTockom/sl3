% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Lrnr_bartMachine.R
\docType{class}
\name{Lrnr_bartMachine}
\alias{Lrnr_bartMachine}
\title{BART Machine Learner}
\format{\code{\link{R6Class}} object.}
\usage{
Lrnr_bartMachine
}
\value{
Learner object with methods for training and prediction. See
\code{\link{Lrnr_base}} for documentation on learners.
}
\description{
This learner implements Bayesian Additive Regression Trees, using the
\code{bartMachine} package.
}
\section{Parameters}{

\describe{
\item{\code{Y}}{Outcome variable.}
\item{\code{X}}{Covariate dataframe.}
\item{\code{newX}}{Optional dataframe to predict the outcome.}
\item{\code{obsWeights}}{Optional observation-level weights (supported but not tested).}
\item{\code{id}}{Optional id to group observations from the same unit (not used
currently).}
\item{\code{family}}{"gaussian" for regression, "binomial" for binary classification.}
\item{\code{num_trees }}{The number of trees to be grown in the sum-of-trees model.}
\item{\code{num_burn_in}}{Number of MCMC samples to be discarded as "burn-in".}
\item{\code{num_iterations_after_burn_in}}{Number of MCMC samples to draw from the
posterior distribution of f(x).}
\item{\code{alpha}}{Base hyperparameter in tree prior for whether a node is
nonterminal or not.}
\item{\code{beta}}{Power hyperparameter in tree prior for whether a node is
nonterminal or not.}
\item{\code{k}}{For regression, k determines the prior probability that E(Y|X) is
contained in the interval (y_{min}, y_{max}), based on a normal
distribution. For example, when k=2, the prior probability is 95\%. For
classification, k determines the prior probability that E(Y|X) is between
(-3,3). Note that a larger value of k results in more shrinkage and a more
conservative fit.}
\item{\code{q}}{Quantile of the prior on the error variance at which the data-based
estimate is placed. Note that the larger the value of q, the more
aggressive the fit as you are placing more prior weight on values lower
than the data-based estimate. Not used for classification.}
\item{\code{nu}}{Degrees of freedom for the inverse chi^2 prior. Not used for
classification.}
\item{\code{verbose }}{Prints information about progress of the algorithm to the
screen.}

}
}

\section{Common Parameters}{


Individual learners have their own sets of parameters. Below is a list of shared parameters, implemented by \code{Lrnr_base}, and shared
by all learners.

\describe{
\item{\code{covariates}}{A character vector of covariates. The learner will use this to subset the covariates for any specified task}
\item{\code{outcome_type}}{A \code{\link{variable_type}} object used to control the outcome_type used by the learner. Overrides the task outcome_type if specified}
\item{\code{...}}{All other parameters should be handled by the invidual learner classes. See the documentation for the learner class you're instantiating}
}
}

\seealso{
Other Learners: \code{\link{Custom_chain}},
  \code{\link{Lrnr_HarmonicReg}}, \code{\link{Lrnr_arima}},
  \code{\link{Lrnr_base}}, \code{\link{Lrnr_bilstm}},
  \code{\link{Lrnr_bound}}, \code{\link{Lrnr_caret}},
  \code{\link{Lrnr_cdf_discretize}},
  \code{\link{Lrnr_cdf_pooled_hazards}},
  \code{\link{Lrnr_condensier}},
  \code{\link{Lrnr_cv_selector}}, \code{\link{Lrnr_cv}},
  \code{\link{Lrnr_dbarts}},
  \code{\link{Lrnr_define_interactions}},
  \code{\link{Lrnr_density_discretize}},
  \code{\link{Lrnr_density_hse}},
  \code{\link{Lrnr_density_semiparametric}},
  \code{\link{Lrnr_earth}}, \code{\link{Lrnr_expSmooth}},
  \code{\link{Lrnr_gam}}, \code{\link{Lrnr_gbm}},
  \code{\link{Lrnr_glm_fast}}, \code{\link{Lrnr_glmnet}},
  \code{\link{Lrnr_glm}}, \code{\link{Lrnr_grf}},
  \code{\link{Lrnr_gts}}, \code{\link{Lrnr_h2o_grid}},
  \code{\link{Lrnr_hal9001}},
  \code{\link{Lrnr_haldensify}}, \code{\link{Lrnr_hts}},
  \code{\link{Lrnr_independent_binomial}},
  \code{\link{Lrnr_lstm}}, \code{\link{Lrnr_mean}},
  \code{\link{Lrnr_multiple_ts}},
  \code{\link{Lrnr_multivariate}}, \code{\link{Lrnr_nnls}},
  \code{\link{Lrnr_optim}}, \code{\link{Lrnr_pca}},
  \code{\link{Lrnr_pkg_SuperLearner}},
  \code{\link{Lrnr_polspline}},
  \code{\link{Lrnr_pooled_hazards}},
  \code{\link{Lrnr_quantregForest}},
  \code{\link{Lrnr_randomForest}},
  \code{\link{Lrnr_ranger}},
  \code{\link{Lrnr_revere_task}}, \code{\link{Lrnr_rfcde}},
  \code{\link{Lrnr_rpart}}, \code{\link{Lrnr_rugarch}},
  \code{\link{Lrnr_screener_coefs}},
  \code{\link{Lrnr_screener_corP}},
  \code{\link{Lrnr_screener_corRank}},
  \code{\link{Lrnr_screener_randomForest}},
  \code{\link{Lrnr_sl}}, \code{\link{Lrnr_solnp_density}},
  \code{\link{Lrnr_solnp}}, \code{\link{Lrnr_stratified}},
  \code{\link{Lrnr_subset_covariates}},
  \code{\link{Lrnr_svm}}, \code{\link{Lrnr_tsDyn}},
  \code{\link{Lrnr_xgboost}}, \code{\link{Pipeline}},
  \code{\link{Stack}}, \code{\link{define_h2o_X}},
  \code{\link{undocumented_learner}}
}
\concept{Learners}
\keyword{data}
